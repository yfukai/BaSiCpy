{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%pip install matplotlib ray\n",
    "#!pip freeze | grep jax\n",
    "#%pip install jax==0.3.22 jaxlib==0.3.22+cuda11.cudnn805 -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install and import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def to_iterator(obj_ids):\n",
    "    while obj_ids:\n",
    "        done, obj_ids = ray.wait(obj_ids)\n",
    "        yield ray.get(done[0])\n",
    "\n",
    "\n",
    "def show_ray_progress(res):\n",
    "    for x in tqdm(to_iterator(res), total=len(res)):\n",
    "        pass\n",
    "    return ray.get(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "workdir = \"/work/fukai/basicpy\"\n",
    "os.makedirs(workdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from jax.lib import xla_bridge\n",
    "\n",
    "print(xla_bridge.get_backend().platform)\n",
    "import jax\n",
    "\n",
    "jax.config.update(\"jax_platform_name\", \"gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from basicpy import BaSiC, datasets, metrics\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from os import path\n",
    "import time\n",
    "from skimage import filters\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics.fourier_L0_norm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Generate test data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make parabola"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_parabola(dim, coef, center):\n",
    "    sizes = [128] * dim\n",
    "    grid = np.array(\n",
    "        np.meshgrid(\n",
    "            *[\n",
    "                np.linspace(-size // 2 + 1 - c, size // 2 - c, size)\n",
    "                for (c, size) in zip(center, sizes)\n",
    "            ],\n",
    "            indexing=\"ij\"\n",
    "        )\n",
    "    )\n",
    "    gradient = np.sum(grid**2, axis=0)\n",
    "    gradient = coef * (np.max(gradient) - gradient) + 10\n",
    "    return gradient / gradient.mean()\n",
    "\n",
    "\n",
    "# Ground truth, for correctness checking\n",
    "\n",
    "params = [\n",
    "    (2, 0.0005, (0, 0)),\n",
    "    (2, 0.005, (0, 0)),\n",
    "    (2, 0.0005, (-20, -20)),\n",
    "    (2, 0.005, (-20, -20)),\n",
    "]\n",
    "\n",
    "flatfield_profiles = [generate_parabola(*ps) for ps in params]\n",
    "\n",
    "for p in flatfield_profiles:\n",
    "    plt.imshow(p)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make images with blobs "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "aim ... add random (uncorrelated) object that show intensity profile different from the fitted flatfield, see how it affects the fitting quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "blob_size = 2\n",
    "blob_dist = lambda: np.random.normal(0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_cluttered_images(\n",
    "    true_flatfield, intensity, n_images, ave_count, blob_dist\n",
    "):\n",
    "    poss = np.array(\n",
    "        [\n",
    "            [\n",
    "                np.random.uniform(\n",
    "                    -size // 2 + 1,\n",
    "                    size // 2,\n",
    "                )\n",
    "                for size in true_flatfield.shape\n",
    "            ]\n",
    "            for _ in range(np.random.poisson(ave_count))\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    images = []\n",
    "    grid = np.array(\n",
    "        np.meshgrid(\n",
    "            *[\n",
    "                np.linspace(-size // 2 + 1, size // 2, size)\n",
    "                for size in true_flatfield.shape\n",
    "            ],\n",
    "            indexing=\"ij\"\n",
    "        )\n",
    "    )\n",
    "    for _ in range(n_images):\n",
    "        image = true_flatfield.copy()\n",
    "        for p in poss:\n",
    "            image += (\n",
    "                np.exp(\n",
    "                    -np.sum((grid - p[:, np.newaxis, np.newaxis]) ** 2, axis=0)\n",
    "                    / 2.0\n",
    "                    / blob_size**2\n",
    "                )\n",
    "                / np.sqrt(2 * np.pi * blob_size**2) ** 2\n",
    "                * blob_dist()\n",
    "            )\n",
    "        image = image * intensity\n",
    "        image = np.clip(image, 0, None)\n",
    "        image = filters.gaussian(np.random.poisson(image), sigma=1, preserve_range=True)\n",
    "        images.append(image)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images = generate_cluttered_images(\n",
    "    flatfield_profiles[0], 100, 100, 100, lambda: np.random.normal(0, 5)\n",
    ")\n",
    "plt.imshow(images[0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_platform_name\", \"gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b = BaSiC(get_darkfield=False)\n",
    "b.fit(np.array(images))\n",
    "plt.subplot(121)\n",
    "plt.imshow(b.flatfield)\n",
    "plt.colorbar()\n",
    "plt.subplot(122)\n",
    "plt.imshow(b.flatfield / np.mean(b.flatfield) - flatfield_profiles[0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(np.median(images, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(202306)\n",
    "repeat = 100\n",
    "blob_dists = {\n",
    "    \"unbiased\": lambda: np.random.normal(0, 5),\n",
    "    \"biased\": lambda: np.random.normal(10, 5),\n",
    "}\n",
    "conditions = list(\n",
    "    product(\n",
    "        range(\n",
    "            len(flatfield_profiles)\n",
    "        ),  # true_flatfield_id (index of flatfield_profiles)\n",
    "        [10, 100, 1000],  # intensity\n",
    "        [0, 10, 100],  # ave_count\n",
    "        [10, 30, 100, 300, 1000],  # n_images\n",
    "        [\"biased\", \"unbiased\"],  # blob_dist_key\n",
    "        range(5),\n",
    "    )\n",
    ")\n",
    "\n",
    "parameters = []\n",
    "imagess = []\n",
    "for (true_flatfield_id, intensity, ave_count, n_images, blob_dist_key, rep) in tqdm(\n",
    "    conditions\n",
    "):\n",
    "    p = {\n",
    "        \"true_flatfield_id\": true_flatfield_id,\n",
    "        \"intensity\": intensity,\n",
    "        \"ave_count\": ave_count,\n",
    "        \"n_images\": n_images,\n",
    "        \"blob_dist_key\": blob_dist_key,\n",
    "        \"rep\": rep,\n",
    "    }\n",
    "    parameters.append(p)\n",
    "    imagess.append(\n",
    "        generate_cluttered_images(\n",
    "            flatfield_profiles[true_flatfield_id],\n",
    "            intensity=intensity,\n",
    "            n_images=n_images,\n",
    "            ave_count=ave_count,\n",
    "            blob_dist=blob_dists[blob_dist_key],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# show_ray_progress(imagess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# imagess = ray.get(imagess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(path.join(workdir, \"wo_darkfield_imagess.pickle\"), \"wb\") as f:\n",
    "    pickle.dump(imagess, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame.from_records(parameters).to_csv(\n",
    "    path.join(workdir, \"wo_darkfield_parameters.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fit images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"]=\"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(path.join(workdir, \"wo_darkfield_imagess.pickle\"), \"rb\") as f:\n",
    "    imagess = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir -p wo_darkfield_imagess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for j, images in enumerate(imagess):\n",
    "    np.save(f\"wo_darkfield_imagess/{j}.npy\", images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del imagess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters_df = pd.read_csv(\n",
    "    path.join(workdir, \"wo_darkfield_parameters.csv\"), index_col=0\n",
    ")\n",
    "# parameters_df = parameters_df.iloc[:900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_platform_name\", \"gpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# parameters_df = pd.DataFrame.from_records(parameters)\n",
    "# ind = (parameters_df[\"n_images\"]<900).values\n",
    "# parameters_df2 = parameters_df[ind].copy()\n",
    "# imagess2 = [imagess[ii] for ii in np.nonzero(ind)[0]]\n",
    "\"\"\"\n",
    "assert len(parameters_df2) == len(imagess2)\n",
    "with open(\"wo_darkfield_imagess2.pickle\",\"wb\") as f:\n",
    "    pickle.dump(imagess2,f)\n",
    "parameters_df2.to_csv(\"wo_darkfield_parameters2.csv\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters_df[\"image_index\"] = np.arange(len(parameters_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flatfields = []\n",
    "baselines = []\n",
    "b = BaSiC(\n",
    "    get_darkfield=False,\n",
    ")\n",
    "estimated_parameters = []\n",
    "b_cpu = BaSiC(\n",
    "    get_darkfield=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_num = len(estimated_parameters)\n",
    "flatfields = flatfields[:current_num]\n",
    "assert len(flatfields) == current_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "current_num, len(flatfields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_platform_name\", \"gpu\")\n",
    "print(jax.devices())\n",
    "jax.config.update(\"jax_platform_name\", \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# q = \"true_flatfield_id==0 and ave_count==100 and blob_dist_key=='unbiased'\"\n",
    "_df = parameters_df  # .query(q)\n",
    "ii = 0\n",
    "\n",
    "for j, p in tqdm(enumerate(_df.to_dict(orient=\"records\")), total=len(_df)):\n",
    "    images = np.load(f\"wo_darkfield_imagess/{j}.npy\")\n",
    "    #!echo {p[\"image_index\"]} > log.txt\n",
    "    for fitting_mode, smoothness_flatfield in product(\n",
    "        [\"ladmap\", \"approximate\"],  # fitting_mode\n",
    "        list(np.logspace(-1, 1.5, 7)),  # smoothness_flatfield\n",
    "    ):\n",
    "        ii = ii + 1\n",
    "        if ii <= current_num:\n",
    "            continue\n",
    "        p2 = p.copy()\n",
    "        p2.update(\n",
    "            {\n",
    "                \"fitting_mode\": fitting_mode,\n",
    "                \"smoothness_flatfield\": smoothness_flatfield,\n",
    "            }\n",
    "        )\n",
    "        #        query = \" and \".join([f\"{k}==@p2['{k}']\" for k,v in list(p2.items()) if k!= \"smoothness_flatfield\"])\n",
    "        #        _df_sel = estimated_parameters_df.query(query)\n",
    "        #        _row = _df_sel[np.isclose(_df_sel[\"smoothness_flatfield\"],p2[\"smoothness_flatfield\"])]\n",
    "        #        assert len(_row) == 1\n",
    "\n",
    "        jax.config.update(\"jax_platform_name\", \"gpu\")\n",
    "        jax.config.update(\"jax_default_device\", jax.devices()[1])\n",
    "        b.fitting_mode = fitting_mode\n",
    "        b.smoothness_flatfield = smoothness_flatfield\n",
    "        start = time.time()\n",
    "        b.fit(images)\n",
    "        stop = time.time()\n",
    "        p2[\"time_gpu\"] = stop - start\n",
    "        flatfields.append(b.flatfield)\n",
    "        baselines.append(b.baseline)\n",
    "\n",
    "        jax.config.update(\"jax_platform_name\", \"cpu\")\n",
    "\n",
    "        if (\n",
    "            p[\"true_flatfield_id\"] == 0\n",
    "            and p[\"ave_count\"] == 100\n",
    "            and p[\"blob_dist_key\"] == \"unbiased\"\n",
    "        ):\n",
    "            b_cpu.fitting_mode = fitting_mode\n",
    "            b_cpu.smoothness_flatfield = smoothness_flatfield\n",
    "            start = time.time()\n",
    "            b_cpu.fit(images)\n",
    "            stop = time.time()\n",
    "            p2[\"time_cpu\"] = stop - start\n",
    "            assert np.allclose(b_cpu.flatfield, b.flatfield)\n",
    "            assert np.allclose(b_cpu.baseline, b.baseline)\n",
    "        else:\n",
    "            b_cpu.fit(datasets.wsi_brain())\n",
    "\n",
    "        estimated_parameters.append(p2)\n",
    "\n",
    "        current_num = len(estimated_parameters)\n",
    "        assert len(flatfields) == current_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimated_parameters_df = pd.DataFrame.from_records(estimated_parameters).reset_index(\n",
    "    drop=True\n",
    ")\n",
    "estimated_parameters_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(estimated_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.save(\"flatfields.npy\", flatfields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(flatfields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimated_parameters_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculate deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "flatfields = np.load(\"flatfields.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(estimated_parameters_df) == len(flatfields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for (i, row), flatfield in zip(estimated_parameters_df.iterrows(), flatfields):\n",
    "    estimated_parameters_df.loc[i, \"deviation\"] = np.mean(\n",
    "        np.abs(flatfield - flatfield_profiles[row[\"true_flatfield_id\"]])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimated_parameters_df.to_csv(\"wo_flatfield_estimated_parameters_df.csv\")\n",
    "estimated_parameters_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate autotune metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimated_parameters_df = pd.read_csv(\n",
    "    \"wo_flatfield_estimated_parameters_df.csv\", index_col=0\n",
    ")\n",
    "estimated_parameters_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(estimated_parameters_df[\"time_gpu\"], estimated_parameters_df[\"time_cpu\"], \".\")\n",
    "plt.xlabel(\"gpu time (s)\")\n",
    "plt.ylabel(\"cpu time (s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert len(flatfields) == len(estimated_parameters_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate histogram ranges "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "ray.shutdown()\n",
    "ray.init(num_cpus=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "histogram_qmin: float = 0.01\n",
    "histogram_qmax: float = 0.99\n",
    "vmin_factor: float = 0.6\n",
    "vrange_factor: float = 1.5\n",
    "histogram_bins: int = 1000\n",
    "histogram_use_fitting_weight: bool = True\n",
    "fourier_l0_norm_image_threshold: float = 0.1\n",
    "fourier_l0_norm_fourier_radius = 10\n",
    "fourier_l0_norm_threshold = 1e-3\n",
    "fourier_l0_norm_cost_coef = 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_vrange(fitting_mode, image_index):\n",
    "    import warnings\n",
    "\n",
    "    warnings.simplefilter(\"ignore\", DeprecationWarning)\n",
    "    b = BaSiC(\n",
    "        get_darkfield=False,\n",
    "    )\n",
    "    images = np.load(f\"wo_darkfield_imagess/{int(image_index)}.npy\")\n",
    "    b.fitting_mode = fitting_mode\n",
    "    b.smoothness_flatfield = 0.1\n",
    "    b.fit(images)\n",
    "    transformed = b.transform(images, timelapse=False)\n",
    "    vmin, vmax = np.quantile(transformed, [histogram_qmin, histogram_qmax])\n",
    "    val_range = (\n",
    "        vmax - vmin * vmin_factor\n",
    "    ) * vrange_factor  # fix the value range for histogram\n",
    "    return (fitting_mode, image_index), val_range\n",
    "\n",
    "\n",
    "ress = []\n",
    "for (fitting_mode, image_index), _ in tqdm(\n",
    "    list(estimated_parameters_df.groupby([\"fitting_mode\", \"image_index\"]))[:]\n",
    "):\n",
    "    ress.append(ray.remote(calc_vrange).remote(fitting_mode, image_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_ray_progress(ress);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vranges = dict(ray.get(ress))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"vranges.pickle\", \"wb\") as f:\n",
    "    pickle.dump(vranges, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calc metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"vranges.pickle\", \"rb\") as f:\n",
    "    vranges = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ress = []\n",
    "\n",
    "\n",
    "def calc_autotune_cost(i, row, flatfield):\n",
    "    images = np.load(f\"wo_darkfield_imagess/{int(row['image_index'])}.npy\")\n",
    "    val_range = vranges[(row[\"fitting_mode\"], int(row[\"image_index\"]))]\n",
    "    b = BaSiC(\n",
    "        get_darkfield=False,\n",
    "    )\n",
    "\n",
    "    b.fitting_mode = row[\"fitting_mode\"]\n",
    "    b.smoothness_flatfield = row[\"smoothness_flatfield\"]\n",
    "    b.flatfield = flatfield\n",
    "    b.darkfield = np.zeros_like(flatfield)\n",
    "    b.baseline = np.ones(images.shape[0])\n",
    "    transformed = b.transform(images, timelapse=False)\n",
    "    entropy_vmin = np.quantile(transformed, histogram_qmin) * vmin_factor\n",
    "    entropy_vmax = entropy_vmin + val_range\n",
    "    e = metrics.entropy(\n",
    "        transformed,\n",
    "        vmin=entropy_vmin,\n",
    "        vmax=entropy_vmax,\n",
    "        bins=histogram_bins,\n",
    "        clip=True,\n",
    "    )\n",
    "    n = metrics.fourier_L0_norm(\n",
    "        b.flatfield,\n",
    "        fourier_l0_norm_image_threshold,\n",
    "        fourier_l0_norm_fourier_radius,\n",
    "    )\n",
    "    cost = metrics.autotune_cost(\n",
    "        transformed,\n",
    "        flatfield,\n",
    "        entropy_vmin=entropy_vmin,\n",
    "        entropy_vmax=entropy_vmax,\n",
    "        histogram_bins=histogram_bins,\n",
    "        fourier_l0_norm_cost_coef=fourier_l0_norm_cost_coef,\n",
    "        fourier_l0_norm_image_threshold=fourier_l0_norm_image_threshold,\n",
    "        fourier_l0_norm_fourier_radius=fourier_l0_norm_fourier_radius,\n",
    "        fourier_l0_norm_threshold=fourier_l0_norm_threshold,\n",
    "    )\n",
    "    return i, e, n, cost\n",
    "\n",
    "\n",
    "for (i, row), flatfield in tqdm(\n",
    "    list(zip(estimated_parameters_df.iterrows(), flatfields))\n",
    "):\n",
    "    ress.append(ray.remote(calc_autotune_cost).remote(i, row, flatfield))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_ray_progress(ress);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, e, n, cost in ray.get(ress):\n",
    "    estimated_parameters_df.loc[i, \"entropy\"] = e\n",
    "    estimated_parameters_df.loc[i, \"fourier_L0_norm\"] = n\n",
    "    estimated_parameters_df.loc[i, \"autotune_cost\"] = cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimated_parameters_df.to_csv(\"wo_flatfield_estimated_parameters_df_with_autotune.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimated_parameters_df = pd.read_csv(\n",
    "    \"wo_flatfield_estimated_parameters_df_with_autotune.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimated_parameters_df.query(\"intensity==1000\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert all(estimated_parameters_df.index == np.arange(len(estimated_parameters_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for (i, row) in tqdm(\n",
    "    list(\n",
    "        estimated_parameters_df.query(\n",
    "            \"intensity==1000 and n_images==1000 and ave_count==0\"\n",
    "        ).iterrows()\n",
    "    )[:6]\n",
    "):\n",
    "    flatfield = flatfields[i]\n",
    "    images = np.load(f\"wo_darkfield_imagess/{int(row['image_index'])}.npy\")\n",
    "    val_range = vranges[(row[\"fitting_mode\"], int(row[\"image_index\"]))]\n",
    "    b = BaSiC(\n",
    "        get_darkfield=False,\n",
    "    )\n",
    "\n",
    "    b.fitting_mode = row[\"fitting_mode\"]\n",
    "    b.smoothness_flatfield = row[\"smoothness_flatfield\"]\n",
    "    b.flatfield = flatfield\n",
    "    b.darkfield = np.zeros_like(flatfield)\n",
    "    b.baseline = np.ones(images.shape[0])\n",
    "    transformed = images / flatfield[np.newaxis]  # b.transform(images, timelapse=False)\n",
    "    entropy_vmin = np.quantile(transformed, histogram_qmin) * vmin_factor\n",
    "    entropy_vmax = entropy_vmin + val_range\n",
    "    e = metrics.entropy(\n",
    "        transformed,\n",
    "        vmin=entropy_vmin,\n",
    "        vmax=entropy_vmax,\n",
    "        bins=histogram_bins,\n",
    "        clip=True,\n",
    "    )\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.subplot(141)\n",
    "    # plt.hist(transformed.flatten(),bins=histogram_bins,range=(entropy_vmin,entropy_vmax))\n",
    "    plt.hist(transformed.flatten(), bins=histogram_bins)  # ,range=(900,1100))\n",
    "    plt.subplot(142)\n",
    "    plt.imshow(images[0])\n",
    "    plt.subplot(143)\n",
    "    plt.imshow(transformed[0])\n",
    "    plt.subplot(144)\n",
    "    plt.imshow(flatfield)\n",
    "    plt.colorbar()\n",
    "    plt.title(f\"entropy={e:.4f}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keys = [\n",
    "    \"true_flatfield_id\",\n",
    "    \"intensity\",\n",
    "    \"ave_count\",\n",
    "    \"n_images\",\n",
    "    \"blob_dist_key\",\n",
    "    \"fitting_mode\",\n",
    "]\n",
    "for vals, grp in estimated_parameters_df.groupby(keys):\n",
    "    if vals[3] < 100:\n",
    "        continue\n",
    "    for rep, grp2 in grp.groupby(\"rep\"):\n",
    "        plt.plot(grp2[\"smoothness_flatfield\"], grp2[\"deviation\"], \"o-\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"deviation (L1 norm)\")\n",
    "    plt.ylabel(\"entropy\")\n",
    "    break\n",
    "    # plt.ylim(1.2,1.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "keys = [\n",
    "    \"true_flatfield_id\",\n",
    "    \"intensity\",\n",
    "    \"ave_count\",\n",
    "    \"n_images\",\n",
    "    \"blob_dist_key\",\n",
    "    \"fitting_mode\",\n",
    "]\n",
    "for vals, grp in estimated_parameters_df.groupby(keys):\n",
    "    if vals[3] < 100:\n",
    "        continue\n",
    "    for rep, grp2 in grp.groupby(\"rep\"):\n",
    "        plt.plot(grp2[\"deviation\"], grp2[\"entropy\"], \"o-\")\n",
    "    # plt.yscale(\"log\")\n",
    "    plt.xlabel(\"deviation (L1 norm)\")\n",
    "    plt.ylabel(\"entropy\")\n",
    "    # plt.ylim(1.2,1.6)\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "b = BaSiC(\n",
    "    get_darkfield=False,\n",
    ")\n",
    "estimated_parameters2 = []\n",
    "b_cpu = BaSiC(\n",
    "    get_darkfield=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "parameters_df=pd.read_csv(path.join(workdir,\"wo_darkfield_parameters.csv\"),index_col=0)\n",
    "#parameters_df = parameters_df.iloc[:900]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\",DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q = \"true_flatfield_id==0 and ave_count==100 and blob_dist_key=='unbiased' and n_images==1000\"\n",
    "_df = parameters_df.query(q)\n",
    "\n",
    "for j,p in tqdm(enumerate(_df.to_dict(orient=\"records\")),total=len(_df)):\n",
    "    images = np.load(f\"wo_darkfield_imagess/{j}.npy\")\n",
    "    #!echo {p[\"image_index\"]} > log.txt\n",
    "    for fitting_mode, smoothness_flatfield in product(\n",
    "        [\"ladmap\", \"approximate\"],  # fitting_mode\n",
    "        list(np.logspace(-1, 1.5, 7)),  # smoothness_flatfield\n",
    "    ):  \n",
    "        p2 = p.copy()\n",
    "        p2.update({\n",
    "            \"fitting_mode\": fitting_mode,\n",
    "            \"smoothness_flatfield\": smoothness_flatfield,\n",
    "        })\n",
    "#        query = \" and \".join([f\"{k}==@p2['{k}']\" for k,v in list(p2.items()) if k!= \"smoothness_flatfield\"])\n",
    "#        _df_sel = estimated_parameters_df.query(query)\n",
    "#        _row = _df_sel[np.isclose(_df_sel[\"smoothness_flatfield\"],p2[\"smoothness_flatfield\"])]\n",
    "#        assert len(_row) == 1\n",
    "        \n",
    "        jax.config.update('jax_platform_name', 'cpu')\n",
    "        \n",
    "        b_cpu.fitting_mode=fitting_mode\n",
    "        b_cpu.smoothness_flatfield=smoothness_flatfield\n",
    "        start = time.time()\n",
    "        b_cpu.fit(images)\n",
    "        stop = time.time()\n",
    "        \n",
    "        p2[\"time_cpu\"] = stop-start\n",
    "\n",
    "        jax.config.update('jax_platform_name', 'gpu')\n",
    "        jax.config.update(\"jax_default_device\", jax.devices()[1])\n",
    "        \n",
    "        b.fitting_mode=fitting_mode\n",
    "        b.smoothness_flatfield=smoothness_flatfield\n",
    "        start = time.time()\n",
    "        b.fit(images)        \n",
    "        stop = time.time() \n",
    "        p2[\"time_gpu\"] = stop-start\n",
    "        assert np.allclose(b_cpu.flatfield,b.flatfield)\n",
    "        assert np.allclose(b_cpu.baseline,b.baseline)\n",
    "\n",
    "        estimated_parameters2.append(p2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "estimated_parameters_df2 = pd.DataFrame.from_records(estimated_parameters2).reset_index(drop=True)\n",
    "estimated_parameters_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    estimated_parameters_df2[\"time_cpu\"],\n",
    "    estimated_parameters_df2[\"time_gpu\"],\".\"\n",
    ")\n",
    "plt.xlim(0,2)\n",
    "plt.ylim(0,2)\n",
    "plt.plot([0,2],[0,2])\n",
    "plt.xlabel(\"CPU time[s]\")\n",
    "plt.ylabel(\"GPU time[s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
